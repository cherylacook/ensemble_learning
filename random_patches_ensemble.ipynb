{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538be11f-ab7e-4ad0-80b2-e4a413a1764f",
   "metadata": {},
   "source": [
    "# Random Patches Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107f044e-f0bf-426b-8842-6619315a31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "class RandomPatches(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=10, max_features=2, custom_voting=\"majority\"):\n",
    "        self.n_estimators = n_estimators \n",
    "        self.max_features = max_features \n",
    "        self.custom_voting = custom_voting\n",
    "        self.learners = [] # stores the trained base classifiers\n",
    "        self.subspaces = [] # stores the feature subsets used by each learner\n",
    "        self.oob_scores = [] # out-of-bag (accuracy) scores for each learner\n",
    "        self.oob_sets_size = [] # number of elements in out-of-bag samples\n",
    "    \n",
    "    def fit(self, X, y): # trains the ensemble by creating subspaces and fitting a decision tree classifier to each subset\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "        y = y.values if isinstance(y, pd.Series) else y\n",
    " \n",
    "        # total number of instances and total number of features\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # for every member in the ensemble....\n",
    "        # Should select the patches (subsets of instances and features) and train a DecisionTreeClassifier()\n",
    "        # Also calculate the accuracy score for the oob and append it to oob_scores\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Bootstrap sampling (sampling with replacement) of instances \n",
    "            bootstrap_sample_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "            # mark instances that were not selected for bootstrap sample as OOD\n",
    "            oob_indices = np.setdiff1d(np.arange(n_samples), bootstrap_sample_indices)\n",
    "\n",
    "            # Get random sample of features without replacement\n",
    "            feature_indices = np.random.choice(n_features, self.max_features, replace=False)\n",
    "\n",
    "            # Train the decision tree using the bootstrap sample and selected features\n",
    "            dt_classifier = DecisionTreeClassifier()\n",
    "            dt_classifier.fit(X[bootstrap_sample_indices][:, feature_indices], y[bootstrap_sample_indices])\n",
    "\n",
    "            # Store the trained decision tree and its corresponding subspace of features\n",
    "            self.learners.append(dt_classifier)\n",
    "            self.subspaces.append(feature_indices)\n",
    "\n",
    "            # Have the learner make predictions on the OOB instances\n",
    "            oob_predictions = dt_classifier.predict(X[oob_indices][:, feature_indices])\n",
    "            # Calculate and store the resulting OOB accuracy\n",
    "            # np.mean() treats '1' as True and '0' as False, so it gives the proportion of correct predictions\n",
    "            oob_accuracy = np.mean(oob_predictions == y[oob_indices]) \n",
    "            self.oob_sets_size.append(len(oob_indices))\n",
    "            self.oob_scores.append(oob_accuracy)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Converting X to a NumPy array if necessary\n",
    "        X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "        \n",
    "        # Collecting predictions from each learner using their respective subspaces\n",
    "        predictions = np.array([learner.predict(X[:, subspace]) for learner, subspace in zip(self.learners, self.subspaces)])\n",
    "        \n",
    "        # Transposing to get a shape of (n_samples, n_estimators)\n",
    "        # where each row is a sample and each column is a prediction from a different learner \n",
    "        predictions = predictions.T\n",
    "    \n",
    "        # Implement a voting mechanism based on the value of 'self.custom_voting'\n",
    "        if self.custom_voting == \"weighted\":\n",
    "            # Weighted voting based on OOB accuracy\n",
    "            weights = np.array(self.oob_scores)  # Converting OOB scores to a NumPy array\n",
    "            # Initialising the weighted votes \n",
    "            weighted_votes = np.zeros((X.shape[0], len(np.unique(predictions.flatten())))) \n",
    "\n",
    "            for s in range(X.shape[0]):  # Iterate over each sample s\n",
    "                for l in range(self.n_estimators):  # Iterate over each learner l\n",
    "                    # predictions[s, l] is the class prediction for sample s by learner l\n",
    "                    # += weights[l] adds the OOB weight of learner l to the corresponding class's vote count for sample s\n",
    "                    # the better the learner's OOB accuracy, the more its prediction will impact the final vote\n",
    "                    weighted_votes[s, int(predictions[s, l])] += weights[l]  \n",
    "    \n",
    "            vote = np.argmax(weighted_votes, axis=1)  # Select class with highest total weight\n",
    "        else: # default voting scheme is majority vote\n",
    "            vote = np.array([np.argmax(np.bincount(predictions[s, :].astype(int))) for s in range(X.shape[0])])\n",
    "            \n",
    "        return vote  # Return the final predicted class for each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece020c-0bc5-47ab-a40d-59c45bd3e6ad",
   "metadata": {},
   "source": [
    "# Data Reading and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e479fa-c581-4b23-8503-6b5e0d4b8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "def load_dataset(dataset_path='electricity2.csv'):\n",
    "    _data = pd.read_csv(dataset_path)\n",
    "    # class label must be the last column\n",
    "    X = _data.iloc[:, :-1]\n",
    "    y = _data.iloc[:, -1]\n",
    "    return (X, y)\n",
    "\n",
    "# train-test split and return accuracy\n",
    "def evaluate_classifier(classifier, X, y, test_size=0.3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# perform experiments in one dataset for several classifiers\n",
    "def run_experiments(classifiers, show_oob=True):\n",
    "    (X_electricity, y_electricity) = load_dataset(dataset_path='electricity2.csv')\n",
    "    \n",
    "    results = []\n",
    "    datasets = {\n",
    "        'Electricity': (X_electricity, y_electricity)\n",
    "    }\n",
    "    \n",
    "    for dataset_name, (X, y) in datasets.items():\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            print(f\"running {clf_name}\")\n",
    "            accuracy, _, _, _, _ = evaluate_classifier(clf, X, y)\n",
    "            results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Classifier': clf_name,\n",
    "                'Accuracy': accuracy\n",
    "            })\n",
    "            if isinstance(clf, RandomPatches) and show_oob:\n",
    "                for i, (subspace, oob_set_size, oob_accuracy) in enumerate(zip(clf.subspaces, clf.oob_sets_size, clf.oob_scores)):\n",
    "                    print(f\"Base Learner {i+1} | Subspace (features): {subspace} | OOB Instances: {oob_set_size} | OOB Accuracy: {oob_accuracy:.4f}\")\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef4b6a-cc67-4d56-b100-ae1015f5854f",
   "metadata": {},
   "source": [
    "# Evaluation with Printed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c48ff4-c098-4a48-a6d7-53dddaf499e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running DecisionTree\n",
      "running Bagging\n",
      "running RandomForest\n",
      "running AdaBoost\n",
      "running XGBoost\n",
      "running RandomPatches(11, 50) (Weighted Vote)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.753053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.800942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.808004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.762174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.804031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Electricity</td>\n",
       "      <td>RandomPatches(11, 50) (Weighted Vote)</td>\n",
       "      <td>0.808077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset                             Classifier  Accuracy\n",
       "0  Electricity                           DecisionTree  0.753053\n",
       "1  Electricity                                Bagging  0.800942\n",
       "2  Electricity                           RandomForest  0.808004\n",
       "3  Electricity                               AdaBoost  0.762174\n",
       "4  Electricity                                XGBoost  0.804031\n",
       "5  Electricity  RandomPatches(11, 50) (Weighted Vote)  0.808077"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "#!pip install xgboost #NOTE: if output is 'xgboost' is unknown, then uncomment this line and rerun cell\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Run the experiments and display results\n",
    "classifiers = {\n",
    "        'DecisionTree': DecisionTreeClassifier(),\n",
    "        'Bagging': BaggingClassifier(n_estimators=20),\n",
    "        'RandomForest': RandomForestClassifier(),\n",
    "        'AdaBoost': AdaBoostClassifier(algorithm=\"SAMME\"),\n",
    "        'XGBoost': XGBClassifier(eval_metric='logloss'),\n",
    "        'RandomPatches(11, 50) (Weighted Vote)': RandomPatches(max_features=11, n_estimators=50, custom_voting=\"weighted\")\n",
    "    }\n",
    "\n",
    "results_df = run_experiments(classifiers, show_oob=False)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8023c-0b12-4794-99eb-7e5eada72eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
